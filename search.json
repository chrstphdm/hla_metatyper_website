[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "n-1.html",
    "href": "n-1.html",
    "title": "N-1 Algorithm",
    "section": "",
    "text": "Let’s considers the following :\nPn correspond to a pair of alleles, where n is the nth algorithm. So we have P1, P2 and P3.\nLet an allele be noted Am, where m is the mth allele of a pair and start from 0 + n. So A1 and A2 belong to the pair P1, A3 and A4 to P2 and finally, A5 and A6 to the pair P3. For each pair, Am and Am+1 are alphanumerically ordered as Am &lt; Am+1. An allele An can be equal to ‘NA’ value.\nResults for a gene/sample can be summarized as:\nP1=(A1;A2),P2=(A3;A4),P3=(A5;A6)\nIn the case where an algorithm does not produce results, it would then be noted Pn=(NA;NA)."
  },
  {
    "objectID": "n-1.html#definitions",
    "href": "n-1.html#definitions",
    "title": "N-1 Algorithm",
    "section": "",
    "text": "Let’s considers the following :\nPn correspond to a pair of alleles, where n is the nth algorithm. So we have P1, P2 and P3.\nLet an allele be noted Am, where m is the mth allele of a pair and start from 0 + n. So A1 and A2 belong to the pair P1, A3 and A4 to P2 and finally, A5 and A6 to the pair P3. For each pair, Am and Am+1 are alphanumerically ordered as Am &lt; Am+1. An allele An can be equal to ‘NA’ value.\nResults for a gene/sample can be summarized as:\nP1=(A1;A2),P2=(A3;A4),P3=(A5;A6)\nIn the case where an algorithm does not produce results, it would then be noted Pn=(NA;NA)."
  },
  {
    "objectID": "n-1.html#equality-of-pairs",
    "href": "n-1.html#equality-of-pairs",
    "title": "N-1 Algorithm",
    "section": "Equality of pairs",
    "text": "Equality of pairs\nBecause the alleles are ordered, we can easily compare the pairs. Thus, saying that P1==P2* means that A1==A3 and A2==A4. Let us note comparison_integer the variable that counts the number of equal pairs for gene/sample results. As descibed in ?@tbl-comparison_fields, when all algorithms give the same result, comparison_integer == 7. And as soon as comparison_integer &gt; 0, we have at least one equality between two pairs."
  },
  {
    "objectID": "n-1.html#allele-counting",
    "href": "n-1.html#allele-counting",
    "title": "N-1 Algorithm",
    "section": "Allele counting",
    "text": "Allele counting\nLet us note sorted_freq_alleles the variable that contains the list of alleles of the results of a gene/sample and their counts, noted in the form CPT1#A1;. sorted_freq_alleles variable will always contain the NA count. Thus, in the case of identical homozygotes for the 3 algorithms, we will have 3#A1;0#NA. If no algorithm gives a result, we will have 3#NA. And for identical heterozygotes in the 3 cases, we have 3#A1;3#A2;0#NA."
  },
  {
    "objectID": "n-1.html#description-of-the-algorithm",
    "href": "n-1.html#description-of-the-algorithm",
    "title": "N-1 Algorithm",
    "section": "Description of the algorithm",
    "text": "Description of the algorithm\n\n\n\n\n\n\nflowchart TD\n    A[sorted_freq_alleles contains '3#NA' or '2#NA' ]\n    B[comparison_integer &gt; 0]\n    D[sorted_freq_alleles contains '1#NA']\n    E[sorted_freq_alleles contains '0#NA' && '3#']\n    G[sorted_freq_alleles contains '2#']\n    H([output NA-NA])\n    I([output PAIRS OK])\n    J([output HEMIZYGOT TOCHECK])\n    K([output HEMIZYGOT OK])\n    A --&gt; |yes|H\n    A --&gt; |no|B\n    B --&gt; |yes|I\n    B --&gt; |no|D\n    D --&gt; |yes|G\n    G --&gt; |yes|J\n    G --&gt; |no|H\n    D --&gt; |no|E\n    E --&gt; |yes|K\n    E --&gt; |no|H\n\n\n\n\nFigure 1: Description of N-1 algorithm."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hla_metatyper",
    "section": "",
    "text": "We seek to type alleles for the classical HLA class I and II genes from the QGP cohort data containing 14,669 samples to create an imputation database. These data are WGS and we have at our disposal BAMs files aligned to HG38 using an alt-aware mapper. To do so, we selected 3 different typers (HISATGenotype, HLA-HD and T1K) for which scripts to update the index files on the IMGT/HLA 3.49 database have been developed. An in-house script has been developed to extract the relevant reads from the BAM files before entering them into the different typer files. The typing data (26 common genes, 3 field resolution) from the 3 typers are processed using an in-house N-1 algorithm to stratify the results. An imputation base built from the most qualitative data is then constructed, and allows us to type new WGS data very quickly.\n\n\nMost typers are provided with outdated index files. Considering that the IMGT HLA database is updated several times a year and that the number of class I and II alleles is increasing significantly, it seemed important to use a recent version and to make sure that the same versions are used between all typers.\n\n\n\nimgthla_alleles"
  },
  {
    "objectID": "index.html#project-purpose",
    "href": "index.html#project-purpose",
    "title": "hla_metatyper",
    "section": "",
    "text": "We seek to type alleles for the classical HLA class I and II genes from the QGP cohort data containing 14,669 samples to create an imputation database. These data are WGS and we have at our disposal BAMs files aligned to HG38 using an alt-aware mapper. To do so, we selected 3 different typers (HISATGenotype, HLA-HD and T1K) for which scripts to update the index files on the IMGT/HLA 3.49 database have been developed. An in-house script has been developed to extract the relevant reads from the BAM files before entering them into the different typer files. The typing data (26 common genes, 3 field resolution) from the 3 typers are processed using an in-house N-1 algorithm to stratify the results. An imputation base built from the most qualitative data is then constructed, and allows us to type new WGS data very quickly.\n\n\nMost typers are provided with outdated index files. Considering that the IMGT HLA database is updated several times a year and that the number of class I and II alleles is increasing significantly, it seemed important to use a recent version and to make sure that the same versions are used between all typers.\n\n\n\nimgthla_alleles"
  },
  {
    "objectID": "index.html#running-softwares",
    "href": "index.html#running-softwares",
    "title": "hla_metatyper",
    "section": "Running softwares",
    "text": "Running softwares\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\ndetail the parameters used for each"
  },
  {
    "objectID": "index.html#output-data",
    "href": "index.html#output-data",
    "title": "hla_metatyper",
    "section": "Output data",
    "text": "Output data\n\nHISAT-GENOTYPE\nHisatGenotype generates one output file per typed gene for each samples and each indexes. If no result have been founded for a gene, no output file will be created for this gene.\nOutput will be found by default in a folder called hisatgenotype_out. Each output file is composed of 2 parts : first one describes top ten alleles with the most number of mapped or compatible reads. Second one describes a true alleles list generated after applying a statistical model on the first list.\n\n\nHLAHD\nFor one sample, many files are produced by HLAHD. Only *_final.result.txt and *_gene.est.txt are kept and parsed. First file contains list of allele’s couple for each typed genes (one line per gene, Not typed if no result), second file contains list of “Best Allele Pairs” (1 line per allele couple) with details about number of reads aligned for each exons contained in the index.\n\n\n\n\n\n\nWarning\n\n\n\nFor all samples, some genes (i.e F & W) seems to be un-typable as a Couldn't read result file. message appears in *_final.result.txt\n\n\n\n\nT1K\nT1K’s output parsed is a TSV file (*_genotype.tsv) with, for each line, allele 1 and (if exists) allele 2 descriptions (name, abundance estimation and genotyping quality score). No result for a gene would produce empty description line.\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\ncomparison table of softwares outputs (filetypes, datatypes, type of results)\ncomparison table of softwares scores\nconsider introducing the fact that hisatgenotype provides a list of results while T1k and HLAHD provide pairs of alleles\nremember that the formats obtained by each software are different\nintroduce the idea of parsing each output of each software and producing a shared standard output format\n\n\n\n\n\nData parsing and standard output files\nThe purpose of this step is to obtain a csv file per sample for each algorithm with information on the id of the sample, the name of the algorithm, the scores for the major and minor allele (if it is a heterozygote, only the major one in the opposite case) and several other different meta information for each algorithm. This kind of file will allow us to easily process data with scripts for the next steps. This step does not alter the results, although a default selection of available data in case of a tie is made. Here are the rules followed:\nFor HISATgenotype:\n\nwe keep only the 2 alleles with the best abundance scores from the HISAT genotype list\nin the case of a single allele in the list, it is selected by default, regardless of its abundance score\nfrom position 2 in the list of results (minority allele), in case of equality of score between several alleles, we select only one of the alleles (the first in the list)\n\nFor HLAHD:\n\nwe keep only the number of mapped reads on the first common exons (see ?@tbl-hlahd_genes_exons)\nwe keep only the first two alleles of the result list, even if there are several other pairs with identical numbers of reads\nwe rearrange the alleles of a pair from the highest number of reads to the lowest\n\nFor T1K:\n\nTODO: verify the method\n\n\n\nMerge step\nAt the end of the previous step, we were able to obtain 14,633 x 3 files (i.e 43,699), which represents a considerable fragmentation of the information. This step consists in merging all these files to obtain a single output file, with, for each line, the information of the 3 algorithms (if they exist) for each gene and each sample. Thus, we can more easily compare the results of the 3 algorithms between them.\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\nindicate that a merge stage is also performed that combines all the previously generated standard format files into a single file, containing the data of each gene for each sample on each line\ndescribe the fields of this file, which will allow to quickly perform queries on the data\n\n\n\nAs described in Table 1, 2 comparison fields are added by our script. These allow us to perform simple queries to obtain a list of calls according to the criterion of equality between the algorithms.\n\n\n\nTable 1: Description of the 2 comparison fields added by our script. The comparisons are made ignoring the notion of majority and minority allele. For example, a couple of alleles A and B for HISATgenotype is considered as equal to the couple of alleles B and A for HLA-HD, and would correspond to the comparison bit 100\n\n\n\n\n\ncomparison bits\ncomparison integer\nmeaning\n\n\n\n\n000\n0\nalleles are all different\n\n\n001\n1\nalleles HLA-HD == alleles T1K\n\n\n010\n2\nalleles HISATgenotype == alleles T1K\n\n\n011\n3\nNot possible\n\n\n100\n4\nalleles HISATgenotype == alleles HLA-HD\n\n\n101\n5\nNot possible\n\n\n110\n6\nNot possible\n\n\n111\n7\nalleles are all identical\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\nrecall that HLAHD does not type all the genes, which explains the values at 0\ndescribe the low number of unique alleles for T1K\nList the genes for which a particular effort should be made to increase the number of matching calls\nList the means that can be used to do this (deleting calls considered of poor quality, lowering the definition of alleles, etc.)\n\n\n\n\n\n\n\n\n\nflowchart \n\n    extraction_process{{generate BAMs with selected reads}}-.-&gt;merge_bam\n\n    generate_fastqs{generate\\nFASTQs R1 & R2}\n    merge_bam[merged BAM] --&gt; generate_fastqs\n    generate_fastqs --&gt; fq1\n    generate_fastqs --&gt; fq2\n    \n    merge_bam --&gt;t1k[T1K]\n\n    bed_mhc[\\8 indexes files\\]--&gt;hisat[HISATGENOTYPE]\n\n    subgraph typing HLA genes\n        fq1 --&gt; hisat\n        fq2 --&gt; hisat\n        fq1 --&gt; hlahd[HLAHD]\n        fq2 --&gt; hlahd[HLAHD]\n        t1k --&gt; t1k_report[one\\nT1K report file\\nper sample]\n        hlahd --&gt; hlahd_reports[two\\nHLAHD report files\\nper gene/sample]\n        hisat --&gt; hisat_reports[one\\nHISATGENOTYPE report file\\nper index/gene/sample]\n    end\n\n    subgraph generate tsv\n        hisat_reports --&gt;|for each gene & all indexes|hisat_formater(keep MAX nb_reads aligned\\ncompute score=abundance x nb_reads/100\\nmean of score of indexes per allele\\nextract number of indexes per allele\\nif needed, cast 4-fields to 3-fields\\nif casted, sum of scores & sum of nb_indexes)\n        hlahd_reports --&gt;|for each gene|hlahd_formater(extract nb_reads per gene/allele/exon\\nsum the nb_reads per gene/allele\\nextract nb of exons per gene/allele )\n        t1k_report --&gt;t1k_formater(extract abundance estimation per gene/allele\\nextract genotyping quality pergene/allele)\n        hisat_formater --&gt; hisat_tsv_file[hisat formated tsv file]\n        hlahd_formater --&gt; hlahd_tsv_file[hlahd formated tsv file]\n        t1k_formater --&gt; t1k_tsv_file[t1k formated tsv file]\n        hisat_tsv_file --&gt; merge_tsv{merge tsv files}\n        hlahd_tsv_file --&gt; merge_tsv\n        t1k_tsv_file --&gt; merge_tsv\n    end\n\n    merge_tsv --&gt; all_typers[merged report per sample]\n\n\n\n\nFigure 1: Description of the typing and merging process.\n\n\n\n\n\n\n\nHow to filter results\nBecause all the algorithm used may provide calls for the HLA-DRB3-4-5 genes if some reads are aligned to one of these genes, even if a sample does not actually carry any copy of them, these genes are excluded from the filter step. Moreover, a specific step will be apply later in order to determine which of these genes (if any, and how many) may be associated with the DRB1 gene alleles.\n\n\nHLA-HD\nThis is the only algorithm for which an empirical threshold value exists in the literature (TODO: need more references).\nFrom (Butler-Laporte et al. 2023):\n\n[..] we only used HLA calls with a mean coverage of 10 at exon 2, except for HLA-DRB2 and HLA-DRB8, where a mean coverage of 10 at exon 3 was used since these two genes do not have a second exon.\n\nSo we considered that to be retained, the number of reads of each allele (majority and minority) must be &gt;=10. Value is similar to what we can observed in (Butler-Laporte et al. 2023).\n\n\nT1K\n\n\n\n\n\n\n\nNote\n\n\n\nAs a test, we use the value -log10(5 x 10^-8) as the T1K genotyping quality threshold because this variable is basically a P-VALUE and -log10(5 x 10^-8) is the statistical significance of a result from a GWAS. It is a measure of the level of confidence that the result obtained is significant and cannot be attributed to chance. The larger the result, the higher the confidence level and the higher the T1K genotyping quality value.\n\n\n\n\nHISATgenotype\n\nThe only approach referenced in the literature is shown in (Orenbuch et al. 2020) but it is a bad idea:\n\nThe 10% threshold, previously determined by HISAT-genotype (Kim et al. 2019) for use with whole-genome sequencing, assumes that the abundance of the minor allele does not fall below a tenth of the major allele’s abundance.\n\n\n\n\n\n\n\nNote\n\n\n\nObtaining a quality threshold from the literature for HISATgenotype is very difficult. However, considering the variable coming from HISAT2 and providing a number of aligned reads on each gene, and considering the average size of an exon (150bp) and an intron (1 - 50KB) in the human genome, we will use the value of 200 reads as a threshold. Below this threshold, the HISATgenotype call will be discarded and considered equal to NA."
  },
  {
    "objectID": "index.html#summary-after-filtering",
    "href": "index.html#summary-after-filtering",
    "title": "hla_metatyper",
    "section": "Summary after filtering",
    "text": "Summary after filtering\nAs described in Table 2, 2 quality fields are added by our script. These allow us to perform simple queries to obtain a list of calls according to the criterion of quality filter for each algorithm. And because the comparaison fields describe in Table 1 take into account quality fields, a call that does not meet the quality criteria is considered non-existent and will not be considered in the comparison.\n\n\n\nTable 2: Description of the 2 quality fields added by our script. The quality filter does not erase the data from the output file, allowing to keep traceability. On the other hand, if it is not satisfied, it deactivates the comparison by considering the corresponding call as non-existent.\n\n\n\n\n\nquality bits\nquality integer\nmeaning\n\n\n\n\n000\n0\nall alleles pass quality filters\n\n\n001\n1\nT1K alleles are LOW QUAL\n\n\n010\n2\nHLA-HD alleles are LOW QUAL\n\n\n011\n3\nHLA-HD and T1K alleles are LOW QUAL\n\n\n100\n4\nHISATgenotype alleles are LOW QUAL\n\n\n101\n5\nHISATgenotype and T1K alleles are LOW QUAL\n\n\n110\n6\nHISATgenotype and HLA-HD alleles are LOW QUAL\n\n\n111\n7\nHISATgenotype, HLA-HD and T1K alleles are LOW QUAL"
  },
  {
    "objectID": "typers.html",
    "href": "typers.html",
    "title": "HLA Typers",
    "section": "",
    "text": "HLA-HD (Kawaguchi et al. 2017) is an HLA typing algorithm for short-read sequencing. It consists of constructing an extensive dictionary of HLA alleles, precise mapping of NGS reads, and calculating a score based on weighted read counts to select the most suitable pair of alleles. This method takes into account variation not only in the domain for antigen presentation (G-DOMAIN), but also outside this domain, resulting in 6-digit/3-fields precision.\nFrom (Meng et al. 2019) :\n\nAlthough HLAHD-genotype and HLA-HD may need more computing resources, we recommend using them for NGS-based HLA genotyping because of their higher accuracy and robustness to sequencing depth and read length. We propose that the minimal sequence depth for obtaining more than 90% HLA typing accuracy at the 6-digit allele level is 100X.\n\n\n\n\nT1K (Song et al. 2022) (The ONE genotyper for KIR and HLA) is a bioinformatics software tool designed to accurately infer alleles of polymorphic genes such as KIR and HLA, based on RNA-seq/WES/WGS read alignments to a set of allele reference sequences. This software can distinguish true alleles from false ones, as well as identify novel SNPs and single-cell representation. It is capable of processing both single-end and paired-end sequencing data of any read length.\n\n\n\nHISAT-genotype is based on the HISAT2 (Kim, Langmead, and Salzberg 2017) (Hierarchical Indexing for Spliced Alignment of Transcripts) graph mapper which is well-suited for highly polymorphic areas of the genome, such as the HLA region. It takes FASTQ and BAM files as input, and is effective even with whole-genome sequencing (WGS) data which have a lower coverage than other data types. It produces results with four fields and 8 digits when available.\nFrom (Chen et al. 2021):\n\nAlthough we observed similar or increased accuracy when comparing results from WGS to WES data from the same tool (Table 2), WGS and WES miscalls were not always the same. This is evident when assessing accuracy at the gene level. For example, the increase in overall accuracy of HISAT2 when using WGS data for identifying class II alleles was mainly due to a lower HLA-DRB1 accuracy when using WES data. We next focused on the top performant methods, HLA-HD and HISAT2. Notably, the number of miscalls in HLA I genes was too low to characterize patterns or biases (Table 2;only a maximum of four miscalls). For class II genes, HISAT2 showed the highest number of HLA-DRB1 miscalls when using WES data (Table 3). This is largely due to a higher number of missing calls generated in HLA-DRB1 by HISAT2 in WES than WGS data."
  },
  {
    "objectID": "typers.html#typing-algorithms",
    "href": "typers.html#typing-algorithms",
    "title": "HLA Typers",
    "section": "",
    "text": "HLA-HD (Kawaguchi et al. 2017) is an HLA typing algorithm for short-read sequencing. It consists of constructing an extensive dictionary of HLA alleles, precise mapping of NGS reads, and calculating a score based on weighted read counts to select the most suitable pair of alleles. This method takes into account variation not only in the domain for antigen presentation (G-DOMAIN), but also outside this domain, resulting in 6-digit/3-fields precision.\nFrom (Meng et al. 2019) :\n\nAlthough HLAHD-genotype and HLA-HD may need more computing resources, we recommend using them for NGS-based HLA genotyping because of their higher accuracy and robustness to sequencing depth and read length. We propose that the minimal sequence depth for obtaining more than 90% HLA typing accuracy at the 6-digit allele level is 100X.\n\n\n\n\nT1K (Song et al. 2022) (The ONE genotyper for KIR and HLA) is a bioinformatics software tool designed to accurately infer alleles of polymorphic genes such as KIR and HLA, based on RNA-seq/WES/WGS read alignments to a set of allele reference sequences. This software can distinguish true alleles from false ones, as well as identify novel SNPs and single-cell representation. It is capable of processing both single-end and paired-end sequencing data of any read length.\n\n\n\nHISAT-genotype is based on the HISAT2 (Kim, Langmead, and Salzberg 2017) (Hierarchical Indexing for Spliced Alignment of Transcripts) graph mapper which is well-suited for highly polymorphic areas of the genome, such as the HLA region. It takes FASTQ and BAM files as input, and is effective even with whole-genome sequencing (WGS) data which have a lower coverage than other data types. It produces results with four fields and 8 digits when available.\nFrom (Chen et al. 2021):\n\nAlthough we observed similar or increased accuracy when comparing results from WGS to WES data from the same tool (Table 2), WGS and WES miscalls were not always the same. This is evident when assessing accuracy at the gene level. For example, the increase in overall accuracy of HISAT2 when using WGS data for identifying class II alleles was mainly due to a lower HLA-DRB1 accuracy when using WES data. We next focused on the top performant methods, HLA-HD and HISAT2. Notably, the number of miscalls in HLA I genes was too low to characterize patterns or biases (Table 2;only a maximum of four miscalls). For class II genes, HISAT2 showed the highest number of HLA-DRB1 miscalls when using WES data (Table 3). This is largely due to a higher number of missing calls generated in HLA-DRB1 by HISAT2 in WES than WGS data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "input.html",
    "href": "input.html",
    "title": "Input Data",
    "section": "",
    "text": "IMGT/HLA is a public database specialized in the field of human histocompatibility. It provides information on HLA genes, which are responsible for immune responses in organ transplantation. The database contains information on the amino acid sequences and protein structures associated with the HLA genes. It also contains information on HLA gene polymorphism, including nucleotide sequences, binding motifs and information on antigens that are recognized by the immune system. Finally, the database contains information on the associations between HLA allotypes and human diseases.\nThe July 2022 version 3.49 contains 929 new alleles, 4 pending alleles, 122 modified alleles, 1 modified suffix and 1 deleted allele compared to the previous version.\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\ndescribe errors in 3.50 and why we use 3.49\ndescribe IMGT data conversion for each algorithm\nexplain different indexes for HISATgenotype"
  },
  {
    "objectID": "input.html#imgthla-data",
    "href": "input.html#imgthla-data",
    "title": "Input Data",
    "section": "",
    "text": "IMGT/HLA is a public database specialized in the field of human histocompatibility. It provides information on HLA genes, which are responsible for immune responses in organ transplantation. The database contains information on the amino acid sequences and protein structures associated with the HLA genes. It also contains information on HLA gene polymorphism, including nucleotide sequences, binding motifs and information on antigens that are recognized by the immune system. Finally, the database contains information on the associations between HLA allotypes and human diseases.\nThe July 2022 version 3.49 contains 929 new alleles, 4 pending alleles, 122 modified alleles, 1 modified suffix and 1 deleted allele compared to the previous version.\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\ndescribe errors in 3.50 and why we use 3.49\ndescribe IMGT data conversion for each algorithm\nexplain different indexes for HISATgenotype"
  },
  {
    "objectID": "input.html#sequencing-data",
    "href": "input.html#sequencing-data",
    "title": "Input Data",
    "section": "Sequencing data",
    "text": "Sequencing data\nThe 3 typers accept Paired-end FASTQ files or BAM files as input.\nHowever, the use of files containing reads already aligned (BAM files) by a typewriter implies that a read extraction step must be executed internally by the typewriter before launching its own alignment algorithm. Our BAM files have been produced with an option allowing our alignment algorithm (bwa TODO) to take into account possible alignments on alternative contigs. Therefore, any read extraction operation must take this information into account in order not to risk missing a certain number of reads.\nReading the T1K source code allowed us to verify that the read extraction step takes alternative alignments into consideration (TODO link). No information was available for HLAHD and HisatGenotype.\nAlthough the documentation of the BAM format is sufficiently detailed, it is currently difficult to find a gold standard, tested and validated method to extract reads aligned to a region shared between a canonical contig and an alternative contig(s). Similarly, there are multiple combinations of software and methods to convert BAM files into FASTQ pair-end files and there are few benchmarks on these methods.\nIn the context of our work where each read can considerably influence the typing result, it appeared essential to test and measure different methods of extraction of reads but also of conversion into FASTQ files.\n\n\n\n\n\n\nflowchart \n    15k_raw_bams[15k raw BAMs]\n    raw_bam[raw BAM]\n    15k_raw_bams--&gt;|for each sample|raw_bam\n    bed_mhc[\\MHC regions + HLA alt contigs\\]\n    \n    subgraph generate BAMs with selected reads\n        mhc_reads_bam[MHC reads BAM]\n        unmapped_reads_bam[UNMAPPED reads BAM]\n        extract_mhc_reads{extract\\nMHC reads}\n        extract_unmapped_reads{extract\\nUNMAPPED reads}\n        bed_mhc--&gt;extract_mhc_reads\n        raw_bam--&gt;extract_mhc_reads\n        extract_mhc_reads--&gt;mhc_reads_bam\n        raw_bam--&gt;extract_unmapped_reads\n        extract_unmapped_reads--&gt;unmapped_reads_bam\n        merge_bam{merged BAM}\n        mhc_reads_bam--&gt;merge_bam\n        unmapped_reads_bam--&gt;merge_bam\n    end\n\n    subgraph generate FASTQs\n        generate_fastqs{generate\\nFASTQs R1 & R2}\n        merge_bam --&gt; generate_fastqs\n        generate_fastqs --&gt; fq1\n        generate_fastqs --&gt; fq2\n    end\n\n\n\n\n\nFigure 1: Description of the reads extraction process.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTODO:\n\ndescribe alt-aware alignment data\nremind that each algo has a step of mapping\ndescribe reads extraction step for each algorithm\ndescribe our method for reads extraction"
  }
]